import { Command } from '../../structures/Command'
import { Instance } from '../../structures/Instance'

import { openai } from '../../lib/openai'
import { getQuotedMessage } from '../../utils/getQuotedMessage'

import {
  downloadMediaMessage,
  type MessageType,
  type WAMessage,
} from '@whiskeysockets/baileys'
import { Buffer } from 'buffer'
import { toFile } from 'openai'

type AudioConfig = {
  prompt: string
  model: string
}

export default class Whisper extends Command {
  constructor(instance: Instance) {
    super(instance, {
      name: 'transcript',
      description:
        'üé§ Converta √°udios para texto utilizando uma intelig√™ncia artificial.',
      credits: 1,
      category: 'Utilidades',
      aliases: ['transcrever'],
      examples: [
        {
          usage: '[marque o √°udio]',
          description: 'Converte o √°udio mencionado para texto.',
        },
      ],
      videoSrc: 'https://www.youtube.com/embed/Tm4W7M9BA2Q',
      note: 'Voc√™ n√£o precisa utilizar comandos para transcrever √°udios. Envie ou encaminhe um √°udio para a conversa do Reth e espere a m√°gica acontecer!',
      premiumOnly: true,
    })
  }

  async execute(message: WAMessage) {
    const author = message.key.participant || message.key.remoteJid
    if (!author) {
      return
    }

    const messageData = message.message
    if (!messageData) {
      return
    }

    const messageType = Object.keys(messageData)[0] as MessageType
    if (!messageType) {
      return
    }

    const chatJid = message.key.remoteJid
    if (!chatJid) {
      return
    }

    const isAudio = messageType === 'audioMessage'
    if (!isAudio) {
      const quotedMessage = await getQuotedMessage(message)
      if (!quotedMessage) {
        return this.instance.socket.sendMessage(
          chatJid,
          { text: '‚ùå O tipo da m√≠dia √© inv√°lido.' },
          { quoted: message },
        )
      }

      message.message = quotedMessage
    }

    const audioBuffer = await downloadMediaMessage(message, 'stream', {}).then(
      (media) => media as Buffer,
    )

    const isDeveloper = this.instance.developersJid.includes(author)

    const audioSize = Number(messageData.audioMessage?.fileLength) / (1024 * 1024)

    if (isDeveloper && audioSize > 5) {
      return this.instance.socket.sendMessage(
        chatJid,
        { text: "‚ùå O √°udio deve ser menor que 5 MB's." },
        { quoted: message },
      )
    }

    const processingMessage = await this.instance.socket.sendMessage(
      chatJid,
      { text: 'üéß Convertendo o √°udio...' },
      { quoted: message },
    )
    if (!processingMessage) {
      return
    }

    const audioConfig: AudioConfig = {
      model: 'whisper-1',
      prompt:
        'Como o √°udio √© de uma mensagem de WhatsApp, pode conter frases informais, sotaques, g√≠rias, palavr√µes, etc.\nO √°udio tamb√©m pode conter palavras de preenchimento comuns, exemplo: "Umm, deixe-me pensar tipo, hmm... Ok, aqui est√° o que eu estou pensando."\nTodas as palavras parecidas com "R√©ti", "R√©t", "R√©te", "Retchi", deve ser "Reth". O idioma deve ser o original do √°udio.',
    }

    try {
      const { text } = await this.transcribeAudio(audioConfig, audioBuffer)

      await this.instance.socket.sendMessage(chatJid, {
        text: text.trim(),
        edit: processingMessage.key,
      })
    } catch (error) {
      await this.instance.socket.sendMessage(chatJid, {
        text:
          '‚õî *Ocorreu um erro ao converter o seu √°udio para texto!*\n‚ñ∏ Envie novamente, ou tente digitar outra coisa.',
        edit: processingMessage.key,
      })

      return console.log('Error to transcribe audio:', error)
    }
  }

  async transcribeAudio({ model, prompt }: AudioConfig, audio: Buffer) {
    const file = await toFile(audio, 'audio.ogg')

    return await openai.audio.transcriptions.create({
      language: 'pt',
      file,
      model,
      prompt,
    })
  }
}
